% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/demo_GSO.R
\name{demo_GSO}
\alias{demo_GSO}
\title{demo_GSO - The demo of GSO package}
\usage{
demo_GSO(
  A,
  B,
  InitialX,
  algorithm,
  sparSequence,
  numCore = 2,
  maxIter = 200,
  path = "Output"
)
}
\arguments{
\item{A}{Gene expression data of transcriptome factors (i.e. feature matrix in machine learning).
The dimension of A is nsample * ntf.}

\item{B}{Gene expression data of target genes (i.e. observation matrix in machine learning).
The dimension of B is nsample * ngene.}

\item{InitialX}{Gene expression data of Chromatin immunoprecipitation or other matrix
(i.e. initial iterative point in machine learning). The dimension of InitialX is ngene * ntf.}

\item{algorithm}{Three group sparse optimization algorithms: Soft, Half and Hard.}

\item{sparSequence}{Sequence of group sparsity level.}

\item{numCore}{Number of cores for computation.}

\item{maxIter}{Maximum iteration used in computation; default as 200.}

\item{path}{Output directory path.}
}
\description{
This is the main function to call algorithms: SoftThr, HalfThr and HardThr.
}
\details{
The demo_GSO function is used to solve group sparse optimization problem via different algorithm.
The SoftThr function aims to solve the problem:
\deqn{\min \|Ax-b\|^2 + \lambda \|x\|_{2,1}}
to obtain s-group sparse solution.

The HardThr function aims to solve the problem:
\deqn{\min \|Ax-b\|^2 + \lambda \|x\|_{2,0}}
to obtain s-group sparse solution.
}
\examples{
ntf <- 30
ngene <- 300
nsample <- 20
A <- matrix(rnorm(ntf*nsample), nrow = nsample, ncol = ntf)
B <- matrix(rnorm(ngene*nsample), nrow = nsample, ncol = ngene)
InitialX <- matrix(rnorm(ntf*ngene), nrow = ngene, ncol = ntf)
sparSeq <- c(1:10,seq(10,20,2))
algorithm <- 'Hard'
TFlist <- paste0('G',1:ntf)
resGSO <- demo_GSO(A, B, InitialX, algorithm, sparSeq)
}
\references{
Y. Hu, C. Li, K. Meng, J. Qin and X. Yang*, Group sparse optimization via Lp,q regularization, Journal of Machine Learning Research, 18(30): 1-52, 2017.
}
\author{
Yaohua Hu \href{mailto:mayhhu@szu.edu.cn}{mayhhu@szu.edu.cn}

Xinlin Hu \href{mailto:thompson-xinlin.hu@connect.polyu.hk}{thompson-xinlin.hu@connect.polyu.hk}
}
